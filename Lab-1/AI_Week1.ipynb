{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, pcost, hcost):\n",
    "        # Initialize node with parent node, state, path cost, and heuristic cost\n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.pcost = pcost\n",
    "        self.hcost = hcost\n",
    "        self.cost = pcost + hcost  # Total cost = path cost + heuristic cost\n",
    "    \n",
    "    def __hash__(self):\n",
    "        # Hash function to generate hash value for the node's state\n",
    "        return hash(''.join(self.state.flatten()))  # Convert state to a hashable string\n",
    "    \n",
    "    def __str__(self):\n",
    "        # String representation of the node's state\n",
    "        return str(self.state)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        # Check if two nodes are equal\n",
    "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten()))  # Compare hash values\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        # Check if two nodes are not equal\n",
    "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))  # Compare hash values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize priority queue as an empty list\n",
    "        self.queue = []\n",
    "        \n",
    "    def push(self, node):\n",
    "        # Add a node to the priority queue\n",
    "        self.queue.append(node)\n",
    "    \n",
    "    def pop(self):\n",
    "        # Remove and return the node with the least cost from the priority queue\n",
    "        \n",
    "        # Initialize variables to keep track of the node with the least cost\n",
    "        next_state = None\n",
    "        state_cost = 10**18  # Initialize with a large number\n",
    "        index = -1  # Initialize index of node with least cost\n",
    "        \n",
    "        # Iterate through the queue to find the node with the least cost\n",
    "        for i in range(len(self.queue)):\n",
    "            if self.queue[i].cost < state_cost:\n",
    "                state_cost = self.queue[i].cost\n",
    "                index = i\n",
    "        \n",
    "        # Remove and return the node with the least cost\n",
    "        return self.queue.pop(index)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        # Check if the priority queue is empty\n",
    "        return len(self.queue) == 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        # String representation of the priority queue\n",
    "        l = []\n",
    "        for i in self.queue:\n",
    "            l.append(i.state)  # Append state of each node to the list\n",
    "        return str(l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Get the length of the priority queue\n",
    "        return len(self.queue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Environment():\n",
    "    \n",
    "    def __init__(self, depth=None, goal_state=None):\n",
    "        # Define actions (1: Up, 2: Down, 3: Right, 4: Left)\n",
    "        self.actions = [1, 2, 3, 4]\n",
    "        self.goal_state = goal_state  # Define goal state of the environment\n",
    "        self.depth = depth  # Define maximum depth of the solution\n",
    "        self.start_state = self.generate_start_state()  # Generate start state\n",
    "    \n",
    "    def generate_start_state(self):\n",
    "        # Generate start state by performing 'depth' random moves from the goal state\n",
    "        \n",
    "        past_state = self.goal_state\n",
    "        i = 0\n",
    "        while i != self.depth:\n",
    "            new_states = self.get_next_states(past_state)\n",
    "            choice = np.random.randint(low=0, high=len(new_states))\n",
    "            \n",
    "            if np.array_equal(new_states[choice], past_state):\n",
    "                continue\n",
    "            \n",
    "            past_state = new_states[choice]\n",
    "            i += 1\n",
    "            \n",
    "        return past_state\n",
    "    \n",
    "    def get_start_state(self):\n",
    "        # Return the start state\n",
    "        return self.start_state\n",
    "    \n",
    "    def get_goal_state(self):\n",
    "        # Return the goal state\n",
    "        return self.goal_state\n",
    "    \n",
    "    def get_next_states(self, state):\n",
    "        # Given a state, return all possible next states\n",
    "        \n",
    "        space = (0, 0)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i, j] == '_':\n",
    "                    space = (i, j)\n",
    "                    break\n",
    "        \n",
    "        new_states = []\n",
    "        \n",
    "        if space[0] > 0:  # Move Up\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0] - 1, space[1]]\n",
    "            new_state[space[0] - 1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[0] < 2:  # Move Down\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0] + 1, space[1]]\n",
    "            new_state[space[0] + 1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        if space[1] < 2:  # Move Right\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1] + 1]\n",
    "            new_state[space[0], space[1] + 1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[1] > 0:  # Move Left\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1] - 1]\n",
    "            new_state[space[0], space[1] - 1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        return new_states\n",
    "    \n",
    "    def reached_goal(self, state):\n",
    "        # Check if the given state is the goal state\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i, j] != self.goal_state[i, j]:\n",
    "                    return False\n",
    "        \n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, env, heuristic):\n",
    "        # Initialize agent with priority queue for frontier, dictionary for explored nodes,\n",
    "        # start state, goal state, environment, goal node, and heuristic function\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = env.get_start_state()\n",
    "        self.goal_state = env.get_goal_state()\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        # Explore the environment and find the goal node\n",
    "        \n",
    "        # Initialize the initial node with start state\n",
    "        init_node = Node(parent=None, state=self.start_state, pcost=0, hcost=0)\n",
    "        self.frontier.push(init_node)\n",
    "        steps = 0\n",
    "        while not self.frontier.is_empty():\n",
    "\n",
    "            curr_node = self.frontier.pop()\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "\n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "            \n",
    "            goal_state = self.env.get_goal_state()\n",
    "\n",
    "            for state in next_states:\n",
    "                # Calculate heuristic cost for next states\n",
    "                hcost = self.heuristic(state, goal_state)\n",
    "                node = Node(parent=curr_node, state=state, pcost=curr_node.pcost + 1, hcost=hcost)\n",
    "                self.frontier.push(node)\n",
    "            steps += 1\n",
    "        \n",
    "        return steps, self.soln_depth()\n",
    "    \n",
    "    def soln_depth(self):\n",
    "        # Calculate solution depth\n",
    "        node = self.goal_node\n",
    "        count = 0\n",
    "        while node is not None:\n",
    "            node = node.parent\n",
    "            count += 1\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    def print_nodes(self):\n",
    "        # Print the path from start node to goal node\n",
    "        \n",
    "        node = self.goal_node\n",
    "        path = []\n",
    "        while node is not None:\n",
    "            path.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in path[::-1]:\n",
    "            print(\"Step:\", step)\n",
    "            print(node)\n",
    "            step += 1\n",
    "    \n",
    "    def get_memory(self):\n",
    "        # Get memory usage\n",
    "        \n",
    "        # Estimate memory usage based on the size of frontier and explored nodes\n",
    "        mem = len(self.frontier) * 56 + len(self.explored) * 56\n",
    "        return mem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic2(curr_state, goal_state):\n",
    "    # Heuristic function that calculates the Manhattan distance between the current state and the goal state\n",
    "    \n",
    "    dist = 0\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ele = curr_state[i, j]  # Current marble\n",
    "            goal_i, goal_j = np.where(goal_state == ele)  # Find position of the same marble in the goal state\n",
    "            d = abs(goal_i[0] - i) + abs(goal_j[0] - j)  # Calculate Manhattan distance\n",
    "            dist += d\n",
    "    \n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start State: \n",
      "[['2' '8' '3']\n",
      " ['6' '_' '4']\n",
      " ['5' '1' '7']]\n",
      "Goal State: \n",
      "[['1' '2' '3']\n",
      " ['8' '_' '4']\n",
      " ['7' '6' '5']]\n"
     ]
    }
   ],
   "source": [
    "depth = 500\n",
    "goal_state = np.array([[1,2,3], [8,'_',4], [7,6,5]])\n",
    "env = Environment(depth, goal_state)\n",
    "print(\"Start State: \")\n",
    "print(env.get_start_state())\n",
    "print(\"Goal State: \")\n",
    "print(goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(env = env, heuristic = heuristic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0001175832748413086 56.0\n",
      "50 0.062335538864135745 15208.48\n",
      "100 0.17607250690460205 37699.2\n",
      "150 0.8281965398788452 103038.88\n",
      "200 0.7005016040802002 100705.92\n",
      "250 0.5602542448043824 91827.68\n",
      "300 1.707741904258728 175056.0\n",
      "350 0.7300944328308105 110492.48\n",
      "400 1.3042884254455567 135346.4\n",
      "450 1.0080248785018922 121304.96\n",
      "500 1.1396568250656127 125048.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "depths = np.arange(0, 501, 50)\n",
    "goal_state = np.array([[1, 2, 3], [8, '_', 4], [7, 6, 5]])\n",
    "times_taken = {}\n",
    "mems = {}\n",
    "\n",
    "# Iterate over different depths\n",
    "for depth in depths:\n",
    "    time_taken = 0\n",
    "    mem = 0\n",
    "    \n",
    "    # Repeat each experiment 50 times\n",
    "    for i in range(50):\n",
    "        # Create environment and agent\n",
    "        env = Environment(depth=depth, goal_state=goal_state)\n",
    "        agent = Agent(env=env, heuristic=heuristic2)\n",
    "        \n",
    "        # Measure time taken\n",
    "        start_time = time()\n",
    "        agent.run()\n",
    "        end_time = time()\n",
    "        time_taken += end_time - start_time\n",
    "        \n",
    "        # Measure memory used\n",
    "        mem += agent.get_memory()\n",
    "    \n",
    "    # Average time taken and memory used\n",
    "    time_taken /= 50\n",
    "    mem /= 50\n",
    "    \n",
    "    # Store results\n",
    "    times_taken[depth] = time_taken\n",
    "    mems[depth] = mem\n",
    "    \n",
    "    # Print results\n",
    "    print(depth, time_taken, mem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
